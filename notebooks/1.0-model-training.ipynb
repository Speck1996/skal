{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SKAL! Model Training\n",
    "Brief Example Notebook on how to train a SKAL! model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_dir = \"datasets/nanotwice/\"\n",
    "dataset_format = \"nanotwice\"\n",
    "model = \"bigan\"\n",
    "config_path = \"config/bigan/nanotwice.yaml\"\n",
    "experiment_dir = \"experiments\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ['TF_GPU_ALLOCATOR'] = \"cuda_malloc_async\"\n",
    "\n",
    "subdirs = os.listdir(os.getcwd())\n",
    "# little workaround. with a properlyb built package this should be useless\n",
    "if \"skal\" not in subdirs:\n",
    "    os.chdir(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skal.utils import utils\n",
    "from skal.experiment.config import Config\n",
    "from skal.experiment.workspace import Workspace\n",
    "from skal.data.folders import FolderFactory\n",
    "from skal.data.augmenters import AugmenterBuilder\n",
    "from skal.data.preprocessors import PreprocessorBuilder\n",
    "from skal.data.dataset_builder import AnomalyDatasetBuilder\n",
    "from skal.models.model_choices import LoaderFactory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.set_gpu()\n",
    "exp_params = utils.load_yaml_file(config_path)\n",
    "config = Config(**exp_params)\n",
    "exp_ws = Workspace(root_dir=experiment_dir)\n",
    "folder = FolderFactory.get_folder(dataset_format, training_dir)\n",
    "\n",
    "training_paths = folder.get_training_paths(shuffle=True, seed=config.seed)\n",
    "print(f\"Found {len(training_paths)} training paths\")\n",
    "\n",
    "preprocessor = PreprocessorBuilder.get_preprocessor(config.preprocessor)\n",
    "augmenter = AugmenterBuilder.augmenter_from_config(config.augmenter)\n",
    "dataset_builder = AnomalyDatasetBuilder(\n",
    "    folder, preprocessor, augmenter=augmenter, seed=config.seed\n",
    ")\n",
    "train_ds, val_ds = dataset_builder.train_val_ds_from_folder(\n",
    "    shuffle=True, batch_size=config.batch_size, val_split=config.val_split)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = LoaderFactory.get_loader(config.model['name'])\n",
    "model = loader.load_model_from_config(config.model, seed=config.seed)\n",
    "trainer = loader.load_trainer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_ws.make_experiment_dirs()\n",
    "\n",
    "print(\"Everything is ready. Starting training...\")\n",
    "trainer.train_model(model, train_ds, val_ds, config, exp_ws)\n",
    "model.save_weights(exp_ws.save_dir)\n",
    "print(\"Job done!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bdbigan",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
